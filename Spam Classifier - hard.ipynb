{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f991d2ab",
   "metadata": {},
   "source": [
    "# Download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b000095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "HARD_HAM_URL = DOWNLOAD_ROOT + \"20021010_hard_ham.tar.bz2\"\n",
    "HAM_2_URL = DOWNLOAD_ROOT + \"20030228_easy_ham_2.tar.bz2\"\n",
    "SPAM_2_URL = DOWNLOAD_ROOT + \"20030228_spam_2.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"full_spam\")\n",
    "\n",
    "URLS = (\n",
    "    (\"ham.tar.bz2\", HAM_URL, \"ham\"), \n",
    "    (\"spam.tar.bz2\", SPAM_URL, \"spam\"),\n",
    "    (\"spam2.tar.bz2\", SPAM_2_URL, \"spam\"),\n",
    "    (\"hard_ham.tar.bz2\", HARD_HAM_URL, \"ham\"),\n",
    "    (\"ham2.tar.bz2\", HAM_2_URL, \"ham\")\n",
    ")\n",
    "\n",
    "def fetch_spam_data(urls=URLS, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "\n",
    "    for filename, url, category in urls:\n",
    "        category_path = os.path.join(spam_path, category)\n",
    "        if not os.path.isdir(category_path):\n",
    "            os.makedirs(category_path) \n",
    "\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path) \n",
    "\n",
    "        with tarfile.open(path) as tar_bz2_file:\n",
    "            for member in tar_bz2_file.getmembers():\n",
    "                # Remove subdiretórios e extrai apenas arquivos\n",
    "                if member.isfile():  \n",
    "                    member.name = os.path.basename(member.name)  # Remove caminhos extras\n",
    "                    tar_bz2_file.extract(member, path=category_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df889fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5729ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11794932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4150"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148d5794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1897"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33fee2",
   "metadata": {},
   "source": [
    "# Parsing the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b97a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        # Retorna um objeto EmailMessage\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a9199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7d8146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Return-Path',\n",
       " 'Delivered-To',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Delivered-To',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'Received',\n",
       " 'From',\n",
       " 'To',\n",
       " 'Cc',\n",
       " 'Subject',\n",
       " 'In-Reply-To',\n",
       " 'References',\n",
       " 'MIME-Version',\n",
       " 'Content-Type',\n",
       " 'Message-Id',\n",
       " 'X-Loop',\n",
       " 'Sender',\n",
       " 'Errors-To',\n",
       " 'X-Beenthere',\n",
       " 'X-Mailman-Version',\n",
       " 'Precedence',\n",
       " 'List-Help',\n",
       " 'List-Post',\n",
       " 'List-Subscribe',\n",
       " 'List-Id',\n",
       " 'List-Unsubscribe',\n",
       " 'List-Archive',\n",
       " 'Date']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_emails[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a846563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wednesday 11 September 2002 16:19 CET Justin Mason wrote:\n",
      "> Malte S. Stretz said:\n",
      ">[...]\n",
      "> > I think we should even add new (GA'd) rules to 2.4x (and/or remove old\n",
      "> > ones) and tag a new 2.50 only if we have a bunch of features worth a\n",
      "> > \"dangerous\" big update. I'd say: Yes, you should expect 2.42 and also\n",
      "> > 2.43+ (but update to 2.41 now).\n",
      ">\n",
      "> I would think adding new rules to, or removing broken rules from, 2.4x\n",
      "> would require some discussion first.  but new GA'd scores are definitely\n",
      "> worth putting in, as the ones there are too wild.\n",
      "\n",
      "I think my mail wasn't very clear ;-) My point was that we should continue \n",
      "releasing new rules and removing broken ones (all based on discussions on \n",
      "this list of course) in the 2.4 branch instead of creating a new 2.5 branch \n",
      "everytime we have a bunch of new rules.\n",
      "\n",
      "A new branch should be openend only if (big) new features are introduced \n",
      "(eg. Bayes) or the interface has changed (spam_level_char=x). As the rules \n",
      "are under fluent development, the user has to update quite regularly. But \n",
      "currently he couldn't be shure if the new release will break anything in \n",
      "his setup (like -F going away). So if we say \"the branches are stable to \n",
      "the outside and just improved under the surface but you have to watch out \n",
      "when you update to a new minor version number\", users and sysadmins could \n",
      "be less reluctant to update.\n",
      "\n",
      "All just IMHO :o)\n",
      "Malte\n",
      "\n",
      "P.S.: I'll be away from my box and my mail account for one week, starting \n",
      "tomorrow. So happy coding for the next week :-)\n",
      "\n",
      "-- \n",
      "--- Coding is art.\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[3000].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93426e05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML>\n",
      "<BODY>\n",
      "</head>\n",
      "\n",
      "<body bgcolor=\"#FFFFFF\">\n",
      "<table width=\"62%\" height=\"218\">\n",
      "  <tr valign=\"top\"> \n",
      "    <td height=\"260\"> \n",
      "      <p><font size=\"3\"><b>Fortunes are literally being made in this great new \n",
      "        marketplace!</b></font></p>\n",
      "      <p>O<font size=\"3\"></font><font size=\"3\">ver <b>$9 Billion</b> in merchandise \n",
      "        was sold on <b>eBay</b> in 2001 by people just like you - <u>right from \n",
      "        their homes</u>! </font></p>\n",
      "      <p><font size=\"3\">Now you too can learn the secrets of <b>successful selling \n",
      "        </b>on<b> eBay</b> and <b>make a staggering income</b> from the comfort \n",
      "        of <b>your own home</b>. If you are <b>motivated</b>, capable of having \n",
      "        an<b> open mind</b>, and can follow simple directions, then <a href=\"http://www.generaledu.com/ebayepubs\">visit \n",
      "        us here.</a> If server busy - <a href=\"http://168.75.161.164/ebayepubs/\">alternate.</a></font></p>\n",
      "      <p><font size=\"2\"> <font size=\"1\">We are strongly against sending unsolicited \n",
      "        emails to those who do not wish to receive our special mailings. You have \n",
      "        opted in to one or more of our affiliate sites requesting to be notified \n",
      "        of any special offers we may run from time to time. We also have attained \n",
      "        the services of an independent 3rd party to overlook list management and \n",
      "        removal services. This is NOT unsolicited email. If you do not wish to \n",
      "        receive further mailings, please <a href=\"http://www.generaledu.com/remove.html\">GO \n",
      "        HERE</a> to be removed from the list. Please accept our apologies if you \n",
      "        have been sent this email in error. </font></font></p>\n",
      "      </td>\n",
      "  </tr>\n",
      "</table>\n",
      "<p>&nbsp;</p>\n",
      "<p>&nbsp; </p>\n",
      "<p>&nbsp;</p>\n",
      "<p>&nbsp; </p>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "<p><p><p><p><p><p><p><p><p><p>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<html><p><head><p><meta http-equiv=\"Content-Type\" content=\"text/html; <p>charset=iso-8859-1\"><p><p><p><p><p><p><p><p><p>\n",
      "</BODY>\n",
      "</HTML>\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[900].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f663c3",
   "metadata": {},
   "source": [
    "## Multipart Emails\n",
    "\n",
    "Some emails are multipart, which means they have different sections with different kinds of content (plain text, images, HTML...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a628d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        # if multipart, returns a list of parts\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_structure(sub_email)\n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "264dae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Stores the frequency of each type of email in a dictionary\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42dfd1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 3837),\n",
       " ('text/html', 122),\n",
       " ('multipart(text/plain, application/pgp-signature)', 101),\n",
       " ('multipart(text/plain, text/html)', 58),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 2),\n",
       " ('multipart(text/plain, multipart(text/plain))', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  2),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 2),\n",
       " ('multipart(text/html)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/x-patch)', 1),\n",
       " ('multipart(multipart(text/plain, multipart(text/plain), text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/gif, image/gif, image/gif, image/gif)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, application/ms-tnef)', 1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, text/plain, text/plain)', 1),\n",
       " ('multipart(text/plain, image/png, image/png)', 1),\n",
       " ('multipart(multipart(text/plain, text/html))', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1),\n",
       " ('multipart(text/plain, image/bmp)', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72dee10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 816),\n",
       " ('text/html', 772),\n",
       " ('multipart(text/plain, text/html)', 159),\n",
       " ('multipart(text/html)', 49),\n",
       " ('multipart(text/plain)', 44),\n",
       " ('multipart(multipart(text/html))', 23),\n",
       " ('multipart(multipart(text/plain, text/html))', 5),\n",
       " ('multipart(text/plain, application/octet-stream, text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 3),\n",
       " ('multipart(text/html, text/plain)', 3),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart/alternative', 2),\n",
       " ('multipart(text/html, image/jpeg)', 2),\n",
       " ('multipart(multipart(text/plain), application/octet-stream)', 2),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/gif)',\n",
       "  1),\n",
       " ('text/plain charset=us-ascii', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart(multipart(text/html), image/gif)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream, application/octet-stream, application/octet-stream)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif, image/jpeg)', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1169075",
   "metadata": {},
   "source": [
    "It is noticeable that the majority of non-spam emails consist solely of text, while spam emails contain a significant amount of HTML structures. Additionally, the \"application/octet-stream\" structure (used when the email server or client cannot precisely determine the file type) is more common in spam emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730a0b9",
   "metadata": {},
   "source": [
    "## Email Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71573a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <ilug-admin@linux.ie>\n",
      "Delivered-To : yyyy@localhost.netnoteinc.com\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 9E1F5441DD\tfor <jm@localhost>; Tue,  6 Aug 2002 06:48:09 -0400 (EDT)\n",
      "Received : from phobos [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 11:48:09 +0100 (IST)\n",
      "Received : from lugh.tuatha.org (root@lugh.tuatha.org [194.125.145.45]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g72LqWv13294 for    <jm-ilug@jmason.org>; Fri, 2 Aug 2002 22:52:32 +0100\n",
      "Received : from lugh (root@localhost [127.0.0.1]) by lugh.tuatha.org    (8.9.3/8.9.3) with ESMTP id WAA31224; Fri, 2 Aug 2002 22:50:17 +0100\n",
      "Received : from bettyjagessar.com (w142.z064000057.nyc-ny.dsl.cnc.net    [64.0.57.142]) by lugh.tuatha.org (8.9.3/8.9.3) with ESMTP id WAA31201 for    <ilug@linux.ie>; Fri, 2 Aug 2002 22:50:11 +0100\n",
      "X-Authentication-Warning : lugh.tuatha.org: Host w142.z064000057.nyc-ny.dsl.cnc.net    [64.0.57.142] claimed to be bettyjagessar.com\n",
      "Received : from 64.0.57.142 [202.63.165.34] by bettyjagessar.com    (SMTPD32-7.06 EVAL) id A42A7FC01F2; Fri, 02 Aug 2002 02:18:18 -0400\n",
      "Message-Id : <1028311679.886@0.57.142>\n",
      "Date : Fri, 02 Aug 2002 23:37:59 +0530\n",
      "To : ilug@linux.ie\n",
      "From : Start Now <startnow2002@hotmail.com>\n",
      "MIME-Version : 1.0\n",
      "Content-Type : text/plain; charset=\"US-ASCII\"; format=\"flowed\"\n",
      "Subject : [ILUG] STOP THE MLM INSANITY\n",
      "Sender : ilug-admin@linux.ie\n",
      "Errors-To : ilug-admin@linux.ie\n",
      "X-Mailman-Version : 1.1\n",
      "Precedence : bulk\n",
      "List-Id : Irish Linux Users' Group <ilug.linux.ie>\n",
      "X-Beenthere : ilug@linux.ie\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(header, \":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de5f23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path : <exmh-workers-admin@spamassassin.taint.org>\n",
      "Delivered-To : yyyy@localhost.netnoteinc.com\n",
      "Received : from localhost (localhost [127.0.0.1])\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id 7106643C34\tfor <jm@localhost>; Wed, 21 Aug 2002 08:33:03 -0400 (EDT)\n",
      "Received : from phobos [127.0.0.1]\tby localhost with IMAP (fetchmail-5.9.0)\tfor jm@localhost (single-drop); Wed, 21 Aug 2002 13:33:03 +0100 (IST)\n",
      "Received : from listman.spamassassin.taint.org (listman.spamassassin.taint.org [66.187.233.211]) by    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g7LCXvZ24654 for    <jm-exmh@jmason.org>; Wed, 21 Aug 2002 13:33:57 +0100\n",
      "Received : from listman.spamassassin.taint.org (localhost.localdomain [127.0.0.1]) by    listman.redhat.com (Postfix) with ESMTP id F12A13EA25; Wed, 21 Aug 2002    08:34:00 -0400 (EDT)\n",
      "Delivered-To : exmh-workers@listman.spamassassin.taint.org\n",
      "Received : from int-mx1.corp.spamassassin.taint.org (int-mx1.corp.spamassassin.taint.org    [172.16.52.254]) by listman.redhat.com (Postfix) with ESMTP id 750D33F945    for <exmh-workers@listman.redhat.com>; Wed, 21 Aug 2002 08:30:55 -0400    (EDT)\n",
      "Received : (from mail@localhost) by int-mx1.corp.spamassassin.taint.org (8.11.6/8.11.6)    id g7LCUqx17585 for exmh-workers@listman.redhat.com; Wed, 21 Aug 2002    08:30:52 -0400\n",
      "Received : from mx1.spamassassin.taint.org (mx1.spamassassin.taint.org [172.16.48.31]) by    int-mx1.corp.redhat.com (8.11.6/8.11.6) with SMTP id g7LCUqY17578 for    <exmh-workers@redhat.com>; Wed, 21 Aug 2002 08:30:52 -0400\n",
      "Received : from ratree.psu.ac.th ([202.28.97.6]) by mx1.spamassassin.taint.org    (8.11.6/8.11.6) with SMTP id g7LCGNl23207 for <exmh-workers@redhat.com>;    Wed, 21 Aug 2002 08:16:24 -0400\n",
      "Received : from delta.cs.mu.OZ.AU (delta.coe.psu.ac.th [172.30.0.98]) by    ratree.psu.ac.th (8.11.6/8.11.6) with ESMTP id g7LCUIl27286;    Wed, 21 Aug 2002 19:30:19 +0700 (ICT)\n",
      "Received : from munnari.OZ.AU (localhost [127.0.0.1]) by delta.cs.mu.OZ.AU    (8.11.6/8.11.6) with ESMTP id g7LCU1W09629; Wed, 21 Aug 2002 19:30:01    +0700 (ICT)\n",
      "From : Robert Elz <kre@munnari.OZ.AU>\n",
      "To : Chris Garrigues <cwg-dated-1030314468.7c7c85@DeepEddy.Com>\n",
      "Cc : exmh-workers@spamassassin.taint.org\n",
      "Subject : Re: New Sequences Window\n",
      "In-Reply-To : <1029882468.3116.TMDA@deepeddy.vircio.com>\n",
      "References : <1029882468.3116.TMDA@deepeddy.vircio.com>\n",
      "MIME-Version : 1.0\n",
      "Content-Type : text/plain; charset=\"us-ascii\"\n",
      "Message-Id : <9627.1029933001@munnari.OZ.AU>\n",
      "X-Loop : exmh-workers@spamassassin.taint.org\n",
      "Sender : exmh-workers-admin@spamassassin.taint.org\n",
      "Errors-To : exmh-workers-admin@spamassassin.taint.org\n",
      "X-Beenthere : exmh-workers@spamassassin.taint.org\n",
      "X-Mailman-Version : 2.0.1\n",
      "Precedence : bulk\n",
      "List-Help : <mailto:exmh-workers-request@spamassassin.taint.org?subject=help>\n",
      "List-Post : <mailto:exmh-workers@spamassassin.taint.org>\n",
      "List-Subscribe : <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,    <mailto:exmh-workers-request@redhat.com?subject=subscribe>\n",
      "List-Id : Discussion list for EXMH developers <exmh-workers.spamassassin.taint.org>\n",
      "List-Unsubscribe : <https://listman.spamassassin.taint.org/mailman/listinfo/exmh-workers>,    <mailto:exmh-workers-request@redhat.com?subject=unsubscribe>\n",
      "List-Archive : <https://listman.spamassassin.taint.org/mailman/private/exmh-workers/>\n",
      "Date : Wed, 21 Aug 2002 19:30:01 +0700\n"
     ]
    }
   ],
   "source": [
    "for header, value in ham_emails[0].items():\n",
    "    print(header, \":\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff20d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ILUG] STOP THE MLM INSANITY'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0fdd8",
   "metadata": {},
   "source": [
    "## Spliting training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b34b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0]* len(ham_emails) + [1]*len(spam_emails))\n",
    "\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e856ec3",
   "metadata": {},
   "source": [
    "## Preprocessing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25ef08c",
   "metadata": {},
   "source": [
    "First, we need to convert HTML to plain text. Here we can use html2text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3563edf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<body>\n",
      "<p align=\"center\"><br>\n",
      "<b><font size=\"6\" face=\"Tahoma\" color=\"#000080\">\n",
      "Norton SystemWorks 2002<br>Software Suite<br>\n",
      "Professional Edition</font><br><br>\n",
      "</b><font face=\"Arial\"><b><font size=\"5\"><font color=\"#FF0000\">\n",
      "6 Feature-Packed Utilities,</font> 1 Great Price</font><br>\n",
      "<font size=\"4\">A $300.00+ Combined Retail Value for <font color=\"#FF0000\"> Only $29.99!</font></font><br><br>\n",
      "<font size=\"3\"><span style=\"background-color: #FFFF00\">\n",
      "Protect your computer and your valuable information!<br><br>\n",
      "Don't allow yourself to fall prey to destructive viruses!</span><br><br>\n",
      "<a href=\"http://www.1800mailman.com/software/sw.htm\">CLICK HERE FOR MORE INFO AND TO ORDER</a></font></b><br><br>\n",
      "<font size=\"2\">If you wish to unsubscribe from this list, please <a href=\"http://www.1800mailman.com/removeme.html\"> Click Here</a> to be removed.</font></font></p>\n",
      "</body>\n",
      "</html> ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                   if get_email_structure(email) == \"text/html\"]\n",
    "                    \n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d484ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "**Norton SystemWorks 2002  \n",
      "Software Suite  \n",
      "Professional Edition  \n",
      "  \n",
      "****6 Feature-Packed Utilities, 1 Great Price  \n",
      "A $300.00+ Combined Retail Value for  Only $29.99!  \n",
      "  \n",
      "Protect your computer and your valuable information!  \n",
      "  \n",
      "Don't allow yourself to fall prey to destructive viruses!  \n",
      "  \n",
      "[CLICK HERE FOR MORE INFO AND TO\n",
      "ORDER](http://www.1800mailman.com/software/sw.htm)**  \n",
      "  \n",
      "If you wish to unsubscribe from this list, please [ Click\n",
      "Here](http://www.1800mailman.com/removeme.html) to be removed.\n",
      "\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "from html2text import html2text\n",
    "print(html2text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6165b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        if ctype == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        return html2text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe80e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "**Norton SystemWorks 2002  \n",
      "Software Suite  \n",
      "Professional Edition  \n",
      "  \n",
      "****6 Feature-Packed Utili\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4ba3c",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6453dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5647c04",
   "metadata": {},
   "source": [
    "We also need to replace URLs with the word \"URL\", for this we will use urlextract library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa6e0654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "import urlextract\n",
    "\n",
    "url_extractor = urlextract.URLExtract()\n",
    "print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3927e39",
   "metadata": {},
   "source": [
    "## Word Counters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d1d03",
   "metadata": {},
   "source": [
    "Now we can put all this together intro a transformer that we will use to convert emails to word counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c25b1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "\n",
    "# Custom Transformer\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    # Fit does nothing, since this transformer doesn't learn anything from the data\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    # Get word count\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        \n",
    "        for email in X:\n",
    "            \n",
    "            # Email to text\n",
    "            text = email_to_text(email) or \"\"\n",
    "            \n",
    "            # Uppercase to Lowercase\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "                \n",
    "            # Replace URLs\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            \n",
    "            # Replace numbers\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            \n",
    "            # Replace punctuation\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            \n",
    "            # Count words\n",
    "            word_counts = Counter(text.split())\n",
    "            \n",
    "            # Stemming\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e1f6f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'number': 9, 'and': 6, 'the': 5, 'signal': 4, 'to': 4, 'our': 4, 'advanc': 3, 'cell': 3, 'phone': 3, 'free': 3, 'of': 3, 'each': 3, 'your': 3, 'click': 3, 'world': 2, 'most': 2, 'booster': 2, 'hand': 2, 'headset': 2, 'super': 2, 'is': 2, 'technolog': 2, 'antenna': 2, 'now': 2, 'from': 2, 'purchas': 2, 'in': 2, 'less': 2, 'call': 2, 'ani': 2, 'or': 2, 'on': 2, 'at': 2, 'if': 2, 'you': 2, 'web': 2, 's': 1, 'intern': 1, 'adapt': 1, 'all': 1, 'make': 1, 'model': 1, 'mobil': 1, 'normal': 1, 'price': 1, 'base': 1, 'upon': 1, 'unit': 1, 'bonu': 1, 'radiat': 1, 'shield': 1, 'with': 1, 'util': 1, 'same': 1, 'aerospac': 1, 'use': 1, 'by': 1, 'state': 1, 'art': 1, 'satellit': 1, 'dish': 1, 'receiv': 1, 'which': 1, 'result': 1, 'drop': 1, 'dead': 1, 'zone': 1, 'improv': 1, 'recept': 1, 'build': 1, 'elev': 1, 'hallway': 1, 'tunnel': 1, 'mountain': 1, 'place': 1, 'where': 1, 'a': 1, 'weak': 1, 'don': 1, 't': 1, 'miss': 1, 'that': 1, 'urgent': 1, 'love': 1, 'one': 1, 'dure': 1, 'an': 1, 'emerg': 1, 'natur': 1, 'disast': 1, 'critic': 1, 'situat': 1, 'get': 1, 'also': 1, 'check': 1, 'out': 1, 'lightweight': 1, 'cellular': 1, 'below': 1, 'websit': 1, 'for': 1, 'more': 1, 'inform': 1, 'url': 1, 'are': 1, 'have': 1, 'problem': 1, 'link': 1, 'abov': 1, 'then': 1, 'copi': 1, 'past': 1, 'address': 1, 'into': 1, 'browser': 1, 'wish': 1, 'no': 1, 'longer': 1, 'be': 1, 'includ': 1, 'mail': 1, 'list': 1, 'pleas': 1, 'here': 1, 'mailto': 1, 'remov': 1, 'noucenumbercom': 1, 'write': 1, 'us': 1, 'noucenumb': 1, 'numbernd': 1, 'ave': 1, 'n': 1, 'st': 1, 'petersburg': 1, 'fl': 1}),\n",
       "       Counter({'number': 11, 'to': 11, 'i': 10, 'a': 8, 'rpm': 8, 'the': 7, 'on': 6, 'for': 6, 'and': 6, 'test': 6, 'that': 6, 'my': 5, 'apt': 5, 'it': 5, 'use': 5, 'redhat': 5, 'one': 4, 'own': 4, 'srpm': 4, 's': 4, 'mirror': 4, 'wa': 4, 'at': 3, 'have': 3, 'rh': 3, 'funet': 3, 'be': 3, 'thi': 3, 'base': 3, 'is': 3, 'as': 3, 'of': 3, 'list': 3, 'feb': 2, 'numberpm': 2, 'wrote': 2, 'main': 2, 't': 2, 'repositori': 2, 'directori': 2, 'like': 2, 'currentnumb': 2, 'current': 2, 'gccnumber': 2, 'os': 2, 'network': 2, 'updat': 2, 'stuff': 2, 'topdir': 2, 'someon': 2, 'put': 2, 'url': 2, 'machin': 2, 'veri': 2, 'think': 2, 'but': 2, 'also': 2, 'project': 2, 'seem': 2, 'barri': 2, 'titanium': 2, 'screw': 2, 'sure': 2, 'whi': 2, 'mon': 1, 'peter': 1, 'peltonen': 1, 'fri': 1, 'harri': 1, 'haataja': 1, 'local': 1, 'upgrad': 1, 'from': 1, 'somewher': 1, 'plu': 1, 'orkplac': 1, 'olen': 1, 'ajatellut': 1, 'pystyttää': 1, 'itselleni': 1, 'lokaalin': 1, 'varaston': 1, 'kun': 1, 'suomesta': 1, 'ei': 1, 'tunnu': 1, 'löytyvän': 1, 'julkista': 1, 'peiliä': 1, 'osaisitko': 1, 'avittaa': 1, 'hiukan': 1, 'asiassa': 1, 'eli': 1, 'kuinka': 1, 'lähteä': 1, 'liikkeel': 1, 'ensin': 1, 'kannattane': 1, 'peilata': 1, 'varsinainen': 1, 'n': 1, 'jostain': 1, 'vaan': 1, 'millä': 1, 'softalla': 1, 'rsync': 1, 'ja': 1, 'mistä': 1, 'tuo': 1, 'kannattaa': 1, 'tehdä': 1, 'ajatuksia': 1, 'll': 1, 'post': 1, 'stori': 1, 'here': 1, 'anyway': 1, 'hope': 1, 'no': 1, 'mind': 1, 'may': 1, 'freeli': 1, 'comment': 1, 'or': 1, 'in': 1, 'anoth': 1, 'text': 1, 'tree': 1, 'd': 1, 'number_numb': 1, 'link': 1, 'instal': 1, 'imag': 1, 'throw': 1, 'with': 1, 'makefil': 1, 'after': 1, 'each': 1, 'new': 1, 'packag': 1, 'nice': 1, 'genbasedir': 1, 'progress': 1, 'work': 1, 'you': 1, 'need': 1, 'make': 1, 'releas': 1, 'file': 1, 'pinch': 1, 'exmpl': 1, 'found': 1, 'under': 1, 'apach': 1, 'key': 1, 'all': 1, 'into': 1, 'conf': 1, 'away': 1, 'fi': 1, 'slow': 1, 'tuxfamili': 1, 'when': 1, 'see': 1, 'errata': 1, 'usual': 1, 'so': 1, 'rest': 1, 'shorter': 1, 'path': 1, 'host': 1, 'whole': 1, 'load': 1, 'linux': 1, 'big': 1, 'pub': 1, 'ftp': 1, 'site': 1, 'if': 1, 'there': 1, 'definit': 1, 'mayb': 1, 'they': 1, 'might': 1, 'well': 1, 'doubt': 1, 'would': 1, 'keen': 1, 'fork': 1, 'distribut': 1, 'doesn': 1, 'an': 1, 'easi': 1, 'option': 1, 'should': 1, 'just': 1, 'start': 1, 'quick': 1, 'point': 1, 'out': 1, 'torqu': 1, 'oppos': 1, 'phillip': 1, 'we': 1, 're': 1, 'not': 1, 'matter': 1, 'even': 1, 'littl': 1, 'bit': 1, 'interest': 1, 'mac': 1, 'geek': 1, 'scare': 1, 'us': 1, 'zdnet': 1, 'powerbook': 1, 'review': 1, '_______________________________________________': 1, 'mail': 1, 'freshrpm': 1, 'net': 1}),\n",
       "       Counter({'your': 13, 'you': 12, 'and': 11, 'internet': 6, 'or': 5, 'of': 5, 'the': 5, 'to': 5, 'be': 4, 'pc': 4, 'click': 4, 'is': 3, 'have': 3, 'privaci': 3, 'protect': 3, 'will': 3, 'url': 3, 'it': 3, 'a': 3, 'delet': 3, 'els': 3, 'could': 3, 'easili': 3, 'comput': 3, 'boss': 2, 'out': 2, 'download': 2, 'ez': 2, 'softwar': 2, 'in': 2, 'cach': 2, 'histori': 2, 'not': 2, 'ani': 2, 'web': 2, 'page': 2, 'pictur': 2, 'movi': 2, 'video': 2, 'sound': 2, 'e': 2, 'mail': 2, 'log': 2, 'everyth': 2, 'do': 2, 'recov': 2, 'haunt': 2, 'how': 2, 'would': 2, 'feel': 2, 'if': 2, 'snoop': 2, 'made': 2, 'thi': 2, 'inform': 2, 'public': 2, 'children': 2, 'all': 2, 'on': 2, 'number': 2, 'here': 2, 'dear': 1, 'closr': 1, 'usag': 1, 'track': 1, 'no': 1, 'wife': 1, 'kid': 1, 'find': 1, 're': 1, 'seriou': 1, 'troubl': 1, 's': 1, 'proven': 1, 'fact': 1, 'becaus': 1, 'chat': 1, 'see': 1, 'forev': 1, 'spous': 1, 'mother': 1, 'father': 1, 'neighbor': 1, 'media': 1, 'ruin': 1, 'life': 1, 'solv': 1, 'problem': 1, 'enjoy': 1, 'benefit': 1, 'an': 1, 'as': 1, 'new': 1, 'can': 1, 'speed': 1, 'up': 1, 'browser': 1, 'reclaim': 1, 'hard': 1, 'disk': 1, 'space': 1, 'profession': 1, 'clean': 1, 'one': 1, 'easi': 1, 'mous': 1, 'did': 1, 'know': 1, 'for': 1, 'exampl': 1, 'that': 1, 'everi': 1, 'make': 1, 'window': 1, 'start': 1, 'menu': 1, 'store': 1, 'perman': 1, 'hidden': 1, 'encrypt': 1, 'databas': 1, 'within': 1, 'own': 1, 'keep': 1, 'frighten': 1, 'record': 1, 'both': 1, 'onlin': 1, 'off': 1, 'line': 1, 'activ': 1, 'anyon': 1, 'ever': 1, 'view': 1, 'even': 1, 'mani': 1, 'year': 1, 'later': 1, 'somebodi': 1, 'their': 1, 'friend': 1, 'use': 1, 'what': 1, 'they': 1, 'tri': 1, 'act': 1, 'now': 1, 'stop': 1, 'these': 1, 'file': 1, 'come': 1, 'back': 1, 'from': 1, 'dead': 1, 'remov': 1, 'fryte': 1, 'ponumb': 1, 'kj': 1, '_number': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274b143",
   "metadata": {},
   "source": [
    "## Convert Counters to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f256a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "        \n",
    "    # Learn which words are more common\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items(): \n",
    "                total_count[word] += min(count, 10) # Limit the maximum count to 10 to prevent highly frequent words from dominating the count\n",
    "        # Get the most common words\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        # Creates dictionary that associates words to numerical indices starting at 1\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # Sparse Matriz\n",
    "    # Columns: Email, 0, 1, 2, ... n (0 = unknown word)\n",
    "    # each row contains the number of the email and the frequency of each word\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48cd5dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int32'\n",
       "\twith 30 stored elements and shape (3, 11)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba05884b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[165,   6,   9,   4,   5,   3,   2,   1,   3,   2,   0],\n",
       "       [325,   6,  11,  11,   7,   0,   1,   8,   3,   6,  10],\n",
       "       [227,  11,   2,   5,   5,  13,  12,   3,   5,   2,   0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dc13d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'number': 2,\n",
       " 'to': 3,\n",
       " 'the': 4,\n",
       " 'your': 5,\n",
       " 'you': 6,\n",
       " 'a': 7,\n",
       " 'of': 8,\n",
       " 'on': 9,\n",
       " 'i': 10}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f16d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b00e7f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.950) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.970) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.965) total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9619929734908975"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0d955ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 94.34%\n",
      "Recall: 93.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2546464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3319\n",
      "           1       0.94      0.93      0.94      1518\n",
      "\n",
      "    accuracy                           0.96      4837\n",
      "   macro avg       0.96      0.95      0.95      4837\n",
      "weighted avg       0.96      0.96      0.96      4837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # spam 1 ham 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8185284",
   "metadata": {},
   "source": [
    "Using only the easy ham dataset it was possible to achieve\n",
    "Precision: 95.88%\n",
    "Recall: 97.89%\n",
    "    \n",
    "It seems precision has not decreased that much. On the other hand, recall has dropped a little bit more, which makes sense, since now we have more examples of ham emails that are closer to spam emails, making our model predict more spam emails as ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a5ae6",
   "metadata": {},
   "source": [
    "# Testing other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b76ad6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.939839</td>\n",
       "      <td>0.919343</td>\n",
       "      <td>0.939155</td>\n",
       "      <td>0.864295</td>\n",
       "      <td>0.900172</td>\n",
       "      <td>0.982633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.927228</td>\n",
       "      <td>0.911404</td>\n",
       "      <td>0.896060</td>\n",
       "      <td>0.868906</td>\n",
       "      <td>0.882274</td>\n",
       "      <td>0.966488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.966922</td>\n",
       "      <td>0.957487</td>\n",
       "      <td>0.961277</td>\n",
       "      <td>0.932148</td>\n",
       "      <td>0.946488</td>\n",
       "      <td>0.993387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.951623</td>\n",
       "      <td>0.935436</td>\n",
       "      <td>0.950843</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.920462</td>\n",
       "      <td>0.988188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.960513</td>\n",
       "      <td>0.948170</td>\n",
       "      <td>0.957271</td>\n",
       "      <td>0.915020</td>\n",
       "      <td>0.935669</td>\n",
       "      <td>0.992854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <td>0.961133</td>\n",
       "      <td>0.951303</td>\n",
       "      <td>0.949932</td>\n",
       "      <td>0.924901</td>\n",
       "      <td>0.937250</td>\n",
       "      <td>0.981345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.908414</td>\n",
       "      <td>0.890546</td>\n",
       "      <td>0.862441</td>\n",
       "      <td>0.842556</td>\n",
       "      <td>0.852383</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.831921</td>\n",
       "      <td>0.843028</td>\n",
       "      <td>0.681234</td>\n",
       "      <td>0.872859</td>\n",
       "      <td>0.765232</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.853628</td>\n",
       "      <td>0.787353</td>\n",
       "      <td>0.889423</td>\n",
       "      <td>0.609354</td>\n",
       "      <td>0.723221</td>\n",
       "      <td>0.909979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.737441</td>\n",
       "      <td>0.586691</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.302964</td>\n",
       "      <td>0.929313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.902626</td>\n",
       "      <td>0.891868</td>\n",
       "      <td>0.832804</td>\n",
       "      <td>0.862978</td>\n",
       "      <td>0.847622</td>\n",
       "      <td>0.891868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy  Balanced Accuracy  Precision    Recall  \\\n",
       "AdaBoostClassifier          0.939839           0.919343   0.939155  0.864295   \n",
       "BaggingClassifier           0.927228           0.911404   0.896060  0.868906   \n",
       "ExtraTreesClassifier        0.966922           0.957487   0.961277  0.932148   \n",
       "GradientBoostingClassifier  0.951623           0.935436   0.950843  0.891963   \n",
       "RandomForestClassifier      0.960513           0.948170   0.957271  0.915020   \n",
       "LogisticRegressionCV        0.961133           0.951303   0.949932  0.924901   \n",
       "RidgeClassifierCV           0.908414           0.890546   0.862441  0.842556   \n",
       "Perceptron                  0.831921           0.843028   0.681234  0.872859   \n",
       "KNeighborsClassifier        0.853628           0.787353   0.889423  0.609354   \n",
       "SVC                         0.737441           0.586691   0.907895  0.181818   \n",
       "DecisionTreeClassifier      0.902626           0.891868   0.832804  0.862978   \n",
       "\n",
       "                            F1-Score       AUC  \n",
       "AdaBoostClassifier          0.900172  0.982633  \n",
       "BaggingClassifier           0.882274  0.966488  \n",
       "ExtraTreesClassifier        0.946488  0.993387  \n",
       "GradientBoostingClassifier  0.920462  0.988188  \n",
       "RandomForestClassifier      0.935669  0.992854  \n",
       "LogisticRegressionCV        0.937250  0.981345  \n",
       "RidgeClassifierCV           0.852383       NaN  \n",
       "Perceptron                  0.765232       NaN  \n",
       "KNeighborsClassifier        0.723221  0.909979  \n",
       "SVC                         0.302964  0.929313  \n",
       "DecisionTreeClassifier      0.847622  0.891868  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn import ensemble, linear_model, naive_bayes, neighbors, svm, tree\n",
    "import pandas as pd\n",
    "\n",
    "clf_models = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "    linear_model.LogisticRegressionCV(max_iter=1000, random_state=42),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "    svm.SVC(probability=True),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier() \n",
    "    ]\n",
    "\n",
    "columns = ['Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
    "df_metrics = pd.DataFrame(columns = columns)\n",
    "\n",
    "for clf in clf_models:\n",
    "    try:\n",
    "        clf.fit(X_train_transformed, y_train)\n",
    "        y_pred = clf.predict(X_test_transformed)\n",
    "        y_prob = clf.predict_proba(X_test_transformed)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "        name = clf.__class__.__name__\n",
    "        \n",
    "        metrics = {\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Balanced Accuracy': balanced_accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred),\n",
    "            'Recall': recall_score(y_test, y_pred),\n",
    "            'F1-Score': f1_score(y_test, y_pred),\n",
    "            'AUC': roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "        }\n",
    "        \n",
    "        df_metrics = pd.concat([df_metrics, pd.DataFrame(metrics, index=[name])])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar {clf.__class__.__name__}: {e}\")\n",
    "\n",
    "# Exibindo os resultados\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0601842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c9171_row2_col0, #T_c9171_row2_col1, #T_c9171_row2_col2, #T_c9171_row2_col3, #T_c9171_row2_col4, #T_c9171_row2_col5 {\n",
       "  background-color: #33ff33;\n",
       "}\n",
       "#T_c9171_row3_col2, #T_c9171_row3_col5, #T_c9171_row4_col0, #T_c9171_row4_col1, #T_c9171_row4_col3, #T_c9171_row4_col4 {\n",
       "  background-color: #ff6961;\n",
       "}\n",
       "#T_c9171_row4_col2, #T_c9171_row4_col5, #T_c9171_row5_col0, #T_c9171_row5_col1, #T_c9171_row5_col3, #T_c9171_row5_col4 {\n",
       "  background-color: #ffff33;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c9171\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c9171_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_c9171_level0_col1\" class=\"col_heading level0 col1\" >Balanced Accuracy</th>\n",
       "      <th id=\"T_c9171_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_c9171_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_c9171_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "      <th id=\"T_c9171_level0_col5\" class=\"col_heading level0 col5\" >AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row0\" class=\"row_heading level0 row0\" >AdaBoostClassifier</th>\n",
       "      <td id=\"T_c9171_row0_col0\" class=\"data row0 col0\" >0.939839</td>\n",
       "      <td id=\"T_c9171_row0_col1\" class=\"data row0 col1\" >0.919343</td>\n",
       "      <td id=\"T_c9171_row0_col2\" class=\"data row0 col2\" >0.939155</td>\n",
       "      <td id=\"T_c9171_row0_col3\" class=\"data row0 col3\" >0.864295</td>\n",
       "      <td id=\"T_c9171_row0_col4\" class=\"data row0 col4\" >0.900172</td>\n",
       "      <td id=\"T_c9171_row0_col5\" class=\"data row0 col5\" >0.982633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row1\" class=\"row_heading level0 row1\" >BaggingClassifier</th>\n",
       "      <td id=\"T_c9171_row1_col0\" class=\"data row1 col0\" >0.927228</td>\n",
       "      <td id=\"T_c9171_row1_col1\" class=\"data row1 col1\" >0.911404</td>\n",
       "      <td id=\"T_c9171_row1_col2\" class=\"data row1 col2\" >0.896060</td>\n",
       "      <td id=\"T_c9171_row1_col3\" class=\"data row1 col3\" >0.868906</td>\n",
       "      <td id=\"T_c9171_row1_col4\" class=\"data row1 col4\" >0.882274</td>\n",
       "      <td id=\"T_c9171_row1_col5\" class=\"data row1 col5\" >0.966488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row2\" class=\"row_heading level0 row2\" >ExtraTreesClassifier</th>\n",
       "      <td id=\"T_c9171_row2_col0\" class=\"data row2 col0\" >0.966922</td>\n",
       "      <td id=\"T_c9171_row2_col1\" class=\"data row2 col1\" >0.957487</td>\n",
       "      <td id=\"T_c9171_row2_col2\" class=\"data row2 col2\" >0.961277</td>\n",
       "      <td id=\"T_c9171_row2_col3\" class=\"data row2 col3\" >0.932148</td>\n",
       "      <td id=\"T_c9171_row2_col4\" class=\"data row2 col4\" >0.946488</td>\n",
       "      <td id=\"T_c9171_row2_col5\" class=\"data row2 col5\" >0.993387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row3\" class=\"row_heading level0 row3\" >GradientBoostingClassifier</th>\n",
       "      <td id=\"T_c9171_row3_col0\" class=\"data row3 col0\" >0.951623</td>\n",
       "      <td id=\"T_c9171_row3_col1\" class=\"data row3 col1\" >0.935436</td>\n",
       "      <td id=\"T_c9171_row3_col2\" class=\"data row3 col2\" >0.950843</td>\n",
       "      <td id=\"T_c9171_row3_col3\" class=\"data row3 col3\" >0.891963</td>\n",
       "      <td id=\"T_c9171_row3_col4\" class=\"data row3 col4\" >0.920462</td>\n",
       "      <td id=\"T_c9171_row3_col5\" class=\"data row3 col5\" >0.988188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row4\" class=\"row_heading level0 row4\" >RandomForestClassifier</th>\n",
       "      <td id=\"T_c9171_row4_col0\" class=\"data row4 col0\" >0.960513</td>\n",
       "      <td id=\"T_c9171_row4_col1\" class=\"data row4 col1\" >0.948170</td>\n",
       "      <td id=\"T_c9171_row4_col2\" class=\"data row4 col2\" >0.957271</td>\n",
       "      <td id=\"T_c9171_row4_col3\" class=\"data row4 col3\" >0.915020</td>\n",
       "      <td id=\"T_c9171_row4_col4\" class=\"data row4 col4\" >0.935669</td>\n",
       "      <td id=\"T_c9171_row4_col5\" class=\"data row4 col5\" >0.992854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row5\" class=\"row_heading level0 row5\" >LogisticRegressionCV</th>\n",
       "      <td id=\"T_c9171_row5_col0\" class=\"data row5 col0\" >0.961133</td>\n",
       "      <td id=\"T_c9171_row5_col1\" class=\"data row5 col1\" >0.951303</td>\n",
       "      <td id=\"T_c9171_row5_col2\" class=\"data row5 col2\" >0.949932</td>\n",
       "      <td id=\"T_c9171_row5_col3\" class=\"data row5 col3\" >0.924901</td>\n",
       "      <td id=\"T_c9171_row5_col4\" class=\"data row5 col4\" >0.937250</td>\n",
       "      <td id=\"T_c9171_row5_col5\" class=\"data row5 col5\" >0.981345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row6\" class=\"row_heading level0 row6\" >RidgeClassifierCV</th>\n",
       "      <td id=\"T_c9171_row6_col0\" class=\"data row6 col0\" >0.908414</td>\n",
       "      <td id=\"T_c9171_row6_col1\" class=\"data row6 col1\" >0.890546</td>\n",
       "      <td id=\"T_c9171_row6_col2\" class=\"data row6 col2\" >0.862441</td>\n",
       "      <td id=\"T_c9171_row6_col3\" class=\"data row6 col3\" >0.842556</td>\n",
       "      <td id=\"T_c9171_row6_col4\" class=\"data row6 col4\" >0.852383</td>\n",
       "      <td id=\"T_c9171_row6_col5\" class=\"data row6 col5\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row7\" class=\"row_heading level0 row7\" >Perceptron</th>\n",
       "      <td id=\"T_c9171_row7_col0\" class=\"data row7 col0\" >0.831921</td>\n",
       "      <td id=\"T_c9171_row7_col1\" class=\"data row7 col1\" >0.843028</td>\n",
       "      <td id=\"T_c9171_row7_col2\" class=\"data row7 col2\" >0.681234</td>\n",
       "      <td id=\"T_c9171_row7_col3\" class=\"data row7 col3\" >0.872859</td>\n",
       "      <td id=\"T_c9171_row7_col4\" class=\"data row7 col4\" >0.765232</td>\n",
       "      <td id=\"T_c9171_row7_col5\" class=\"data row7 col5\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row8\" class=\"row_heading level0 row8\" >KNeighborsClassifier</th>\n",
       "      <td id=\"T_c9171_row8_col0\" class=\"data row8 col0\" >0.853628</td>\n",
       "      <td id=\"T_c9171_row8_col1\" class=\"data row8 col1\" >0.787353</td>\n",
       "      <td id=\"T_c9171_row8_col2\" class=\"data row8 col2\" >0.889423</td>\n",
       "      <td id=\"T_c9171_row8_col3\" class=\"data row8 col3\" >0.609354</td>\n",
       "      <td id=\"T_c9171_row8_col4\" class=\"data row8 col4\" >0.723221</td>\n",
       "      <td id=\"T_c9171_row8_col5\" class=\"data row8 col5\" >0.909979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row9\" class=\"row_heading level0 row9\" >SVC</th>\n",
       "      <td id=\"T_c9171_row9_col0\" class=\"data row9 col0\" >0.737441</td>\n",
       "      <td id=\"T_c9171_row9_col1\" class=\"data row9 col1\" >0.586691</td>\n",
       "      <td id=\"T_c9171_row9_col2\" class=\"data row9 col2\" >0.907895</td>\n",
       "      <td id=\"T_c9171_row9_col3\" class=\"data row9 col3\" >0.181818</td>\n",
       "      <td id=\"T_c9171_row9_col4\" class=\"data row9 col4\" >0.302964</td>\n",
       "      <td id=\"T_c9171_row9_col5\" class=\"data row9 col5\" >0.929313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c9171_level0_row10\" class=\"row_heading level0 row10\" >DecisionTreeClassifier</th>\n",
       "      <td id=\"T_c9171_row10_col0\" class=\"data row10 col0\" >0.902626</td>\n",
       "      <td id=\"T_c9171_row10_col1\" class=\"data row10 col1\" >0.891868</td>\n",
       "      <td id=\"T_c9171_row10_col2\" class=\"data row10 col2\" >0.832804</td>\n",
       "      <td id=\"T_c9171_row10_col3\" class=\"data row10 col3\" >0.862978</td>\n",
       "      <td id=\"T_c9171_row10_col4\" class=\"data row10 col4\" >0.847622</td>\n",
       "      <td id=\"T_c9171_row10_col5\" class=\"data row10 col5\" >0.891868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2c346f85ad0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight(s):\n",
    "  is_max = s == s.max()\n",
    "  is_second_max = s == s.nlargest(2).iloc[-1]\n",
    "  is_third_max = s == s.nlargest(3).iloc[-1]\n",
    "\n",
    "  return ['background-color: #33ff33' if is_max.iloc[i] else\n",
    "        'background-color: #ffff33' if is_second_max.iloc[i] else\n",
    "        'background-color: #ff6961' if is_third_max.iloc[i] else\n",
    "        '' for i in range(len(s))]\n",
    "\n",
    "df_metrics = df_metrics.style.apply(highlight)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd061d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning\n",
    "\n",
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a588bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.955) total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.953) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.975) total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.95544554, 0.9528536 , 0.9751861 ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_trees_clf = ensemble.ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "CV_score = cross_val_score(extra_trees_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
    "CV_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33b73e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.98%\n",
      "Recall: 92.69%\n"
     ]
    }
   ],
   "source": [
    "extra_trees_clf.fit(X_train_transformed, y_train)\n",
    "y_pred = extra_trees_clf.predict(X_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8382c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_features': ['sqrt', 5, 7, 9]\n",
    "}\n",
    "\n",
    "extra_trees = ensemble.ExtraTreesClassifier(random_state=42)\n",
    "grid_extra_trees = GridSearchCV(extra_trees, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f876f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=ExtraTreesClassifier(random_state=42),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, 5, 7, 9],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 6, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 250, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=ExtraTreesClassifier(random_state=42),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, 5, 7, 9],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 6, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 250, 500]})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: ExtraTreesClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(min_samples_split=6, n_estimators=250, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ExtraTreesClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\">?<span>Documentation for ExtraTreesClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ExtraTreesClassifier(min_samples_split=6, n_estimators=250, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=ExtraTreesClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_features': ['sqrt', 5, 7, 9],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 6, 10],\n",
       "                         'n_estimators': [100, 250, 500]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_extra_trees.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e26889bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_extra_trees.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43957146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3319\n",
      "           1       0.97      0.93      0.95      1518\n",
      "\n",
      "    accuracy                           0.97      4837\n",
      "   macro avg       0.97      0.96      0.96      4837\n",
      "weighted avg       0.97      0.97      0.97      4837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_extra_trees.best_estimator_\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2a12113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 96.59%\n",
      "Recall: 93.21%\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ad625f",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66241ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 20, None],    \n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],       \n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "log_clf = ensemble.RandomForestClassifier(random_state=42)\n",
    "grid_random_forest_clf = GridSearchCV(log_clf, param_grid)\n",
    "grid_random_forest_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "grid_random_forest_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b06587f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96694215, 0.96694215, 0.96280992, 0.95867769, 0.98760331])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_clf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "CV_score = cross_val_score(random_forest_clf, X_train_transformed, y_train)\n",
    "CV_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1677cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3319\n",
      "           1       0.96      0.91      0.94      1518\n",
      "\n",
      "    accuracy                           0.96      4837\n",
      "   macro avg       0.96      0.95      0.95      4837\n",
      "weighted avg       0.96      0.96      0.96      4837\n",
      "\n",
      "Precision: 95.79%\n",
      "Recall: 91.37%\n"
     ]
    }
   ],
   "source": [
    "random_forest_clf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "random_forest_clf.fit(X_train_transformed, y_train)\n",
    "y_pred = random_forest_clf.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3093ad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3319\n",
      "           1       0.96      0.91      0.94      1518\n",
      "\n",
      "    accuracy                           0.96      4837\n",
      "   macro avg       0.96      0.95      0.95      4837\n",
      "weighted avg       0.96      0.96      0.96      4837\n",
      "\n",
      "Precision: 95.79%\n",
      "Recall: 91.37%\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_random_forest_clf.best_estimator_\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5c05d9",
   "metadata": {},
   "source": [
    "The hyperparameters obtained through Grid Search are the same as the base model's parameters, which is why both have the same performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd869d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5aef7d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "75 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "75 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1193, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 63, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dudac\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.84793388        nan 0.94793388 0.93719008 0.84793388        nan\n",
      " 0.94793388 0.93719008 0.84793388        nan 0.94793388 0.93719008\n",
      " 0.93305785        nan 0.95785124 0.95454545 0.93305785        nan\n",
      " 0.95785124 0.95454545 0.93305785        nan 0.95785124 0.95454545\n",
      " 0.94710744        nan 0.96694215 0.96694215 0.94710744        nan\n",
      " 0.96694215 0.96694215 0.94710744        nan 0.96694215 0.96694215\n",
      " 0.95206612        nan 0.96033058 0.95950413 0.95206612        nan\n",
      " 0.96033058 0.96033058 0.95206612        nan 0.96033058 0.96033058\n",
      " 0.94958678        nan 0.95950413 0.95454545 0.94958678        nan\n",
      " 0.9553719  0.9553719  0.94958678        nan 0.9553719  0.9553719 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [200, 500, 1000]\n",
    "}\n",
    "\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "grid_log_clf = GridSearchCV(log_clf, param_grid)\n",
    "grid_log_clf.fit(X_train_transformed, y_train)\n",
    "\n",
    "grid_log_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50160af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3319\n",
      "           1       0.94      0.93      0.94      1518\n",
      "\n",
      "    accuracy                           0.96      4837\n",
      "   macro avg       0.96      0.95      0.95      4837\n",
      "weighted avg       0.96      0.96      0.96      4837\n",
      "\n",
      "Precision: 94.34%\n",
      "Recall: 93.28%\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_clf.fit(X_train_transformed, y_train)\n",
    "y_pred = log_clf.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "431ffd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3319\n",
      "           1       0.94      0.93      0.94      1518\n",
      "\n",
      "    accuracy                           0.96      4837\n",
      "   macro avg       0.96      0.95      0.95      4837\n",
      "weighted avg       0.96      0.96      0.96      4837\n",
      "\n",
      "Precision: 94.34%\n",
      "Recall: 93.28%\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_log_clf.best_estimator_\n",
    "y_pred = best_model.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77e9fa",
   "metadata": {},
   "source": [
    "# Trying to Increase Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec86da9",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13bcf6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': {0: 1, 1: 5},\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid ={\n",
    "    'n_estimators': [100, 250, 500],\n",
    "    'min_samples_split': [2, 6, 10],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'class_weight': [{0: 1, 1: w} for w in [1, 3, 5]]\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=ensemble.ExtraTreesClassifier(), param_grid=param_grid, scoring='recall', cv=3)\n",
    "grid.fit(X_train_transformed, y_train)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41c3af65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96      3319\n",
      "           1       0.88      0.99      0.93      1518\n",
      "\n",
      "    accuracy                           0.95      4837\n",
      "   macro avg       0.93      0.96      0.95      4837\n",
      "weighted avg       0.96      0.95      0.95      4837\n",
      "\n",
      "Precision: 87.50%\n",
      "Recall: 98.68%\n"
     ]
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "y_pred = clf.predict(X_test_transformed)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80cd307",
   "metadata": {},
   "source": [
    "It was possible to increase recall at the cost of precision, specifically the precision of spam emails. This happened because, by increasing the weight of the spam class, the model is forced to correctly identify more instances of this class, making it less cautious when classifying an email as spam, which decreases precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af57cc",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The choice of the most suitable model depends on the goals we want to achieve. If we wanted to maximize the amount of spam identified, we could opt for the last model, which has a higher recall.\n",
    "\n",
    "However, if we wanted to ensure the correctness of predictions and avoid losing important emails that could be incorrectly classified as spam, we should consider models with higher precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
